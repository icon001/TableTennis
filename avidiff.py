import streamlit as st
import cv2
import tempfile
import mediapipe as mp
import numpy as np

def add_spacing(frame_left, frame_right, gap=20, bg_color=(0, 0, 0)):
    # ë†’ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    h1, w1 = frame_left.shape[:2]
    h2, w2 = frame_right.shape[:2]
    target_height = min(h1, h2)

    # ë¹„ìœ¨ ë§ì¶° ë¦¬ì‚¬ì´ì¦ˆ
    frame_left_resized = resize_with_aspect(frame_left, target_height)
    frame_right_resized = resize_with_aspect(frame_right, target_height)

    # gapì— ë§ëŠ” ë¹ˆ ì˜ì—­ ìƒì„±
    spacing = np.full((target_height, gap, 3), bg_color, dtype=np.uint8)

    # ì„¸ ì´ë¯¸ì§€ ë‚˜ë€íˆ í•©ì¹˜ê¸°
    combined = np.hstack((frame_left_resized, spacing, frame_right_resized))
    return combined

# ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í”„ë ˆì„ ë¦¬ì‚¬ì´ì¦ˆ í•¨ìˆ˜
def resize_with_aspect(frame, target_height=360):
    height, width = frame.shape[:2]
    aspect_ratio = width / height
    new_width = int(target_height * aspect_ratio)
    return cv2.resize(frame, (new_width, target_height))

# MediaPipe ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()
mp_drawing = mp.solutions.drawing_utils

st.title("ğŸ“ íƒêµ¬ ìì„¸ ë¹„êµ ë¶„ì„")
st.markdown("ê°•ì‚¬ì™€ ì‚¬ìš©ìì˜ ìì„¸ë¥¼ ë‚˜ë€íˆ ë¶„ì„í•˜ì—¬ ë¹„êµí•©ë‹ˆë‹¤.")

# ì˜ìƒ ì—…ë¡œë“œ
col1, col2 = st.columns(2)
with col1:
    user_video = st.file_uploader("ğŸ‘¤ ì‚¬ìš©ì ì˜ìƒ ì—…ë¡œë“œ", type=["mp4"])
with col2:
    coach_video = st.file_uploader("ğŸ“ ê°•ì‚¬ ì˜ìƒ ì—…ë¡œë“œ", type=["mp4"])

# ë¶„ì„ ë²„íŠ¼
if user_video and coach_video and st.button("ğŸ“Š ìì„¸ ë¹„êµ ì‹œì‘"):
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False) as tmp_user:
        tmp_user.write(user_video.read())
        user_path = tmp_user.name
    with tempfile.NamedTemporaryFile(delete=False) as tmp_coach:
        tmp_coach.write(coach_video.read())
        coach_path = tmp_coach.name

    cap_user = cv2.VideoCapture(user_path)
    cap_coach = cv2.VideoCapture(coach_path)

    stframe = st.empty()

    while cap_user.isOpened() and cap_coach.isOpened():
        ret_user, frame_user = cap_user.read()
        ret_coach, frame_coach = cap_coach.read()

        if not ret_user or not ret_coach:
            break

        # RGB ë³€í™˜ ë° í¬ì¦ˆ ì¶”ì 
        user_rgb = cv2.cvtColor(frame_user, cv2.COLOR_BGR2RGB)
        coach_rgb = cv2.cvtColor(frame_coach, cv2.COLOR_BGR2RGB)

        user_results = pose.process(user_rgb)
        coach_results = pose.process(coach_rgb)

        # í¬ì¦ˆ ëœë“œë§ˆí¬ í‘œì‹œ
        if user_results.pose_landmarks:
            mp_drawing.draw_landmarks(frame_user, user_results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        if coach_results.pose_landmarks:
            mp_drawing.draw_landmarks(frame_coach, coach_results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        # í”„ë ˆì„ ì •ë ¬
        #frame_user_resized = cv2.resize(frame_user, (480, 360))
        frame_user_resized = resize_with_aspect(frame_user, target_height=360)
        #frame_coach_resized = cv2.resize(frame_coach, (480, 360))
        frame_coach_resized = resize_with_aspect(frame_coach, target_height=360)

        # ë†’ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë§ì¶”ê³ , ê°€ë¡œëŠ” ë¹„ìœ¨ ë”°ë¼ ë‹¤ë¥´ê²Œ ì¡°ì ˆë¨
        #combined = np.hstack((frame_user_resized, frame_coach_resized))
        #combined_rgb = cv2.cvtColor(combined, cv2.COLOR_BGR2RGB)

        #stframe.image(combined_rgb, caption="ì‚¬ìš©ì vs ê°•ì‚¬", use_column_width=True)

        combined = add_spacing(frame_user, frame_coach, gap=30)
        combined_rgb = cv2.cvtColor(combined, cv2.COLOR_BGR2RGB)
        stframe.image(combined_rgb, caption="ì‚¬ìš©ì vs ê°•ì‚¬", use_column_width=True)

    cap_user.release()
    cap_coach.release()
